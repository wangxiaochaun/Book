{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenges.** Since this task of recognizing a visual concept (e.g. cat) is relatively trivial for a human to perform, it is worth considering the challenges involved from the perspective of a Computer Vision algorithm. As we present (an inexhaustive) list of challenges below, keep in mind the raw representation of images as a 3-D array of brightness values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Viewpoint variation.** A single instance of an object can be oriented in many ways with respect to the camera.\n",
    "* **Scale variation.** Visual classes often exhibit variation in their size (size in the real world, not only in terms of their extent in the image).\n",
    "* **Deformation.** Many objects of interest are not rigid bodies and can be deformed in extreme ways.\n",
    "* **Occlusion.** The objects of interest can be occluded. Sometimes only a small portion of an object (as little as few pixels) could be visible.\n",
    "* **Illumination conditions.** The effects of illumination are drastic on the pixel level.\n",
    "* **Background clutter.** The objects of interest may blend into their environment, making them hard to identify.\n",
    "* **Intra-class variation.** The classes of interest can often be relatively broad, such as chair. There are many different types of these objects, each with their own appearance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good image classification model must be invariant to the cross product of all these variations, while simultaneously retaining sensitivity to the inter-class variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = unpickle('./cifar-10-batches-py/data_batch_1')\n",
    "train_2 = unpickle('./cifar-10-batches-py/data_batch_2')\n",
    "train_3 = unpickle('./cifar-10-batches-py/data_batch_3')\n",
    "train_4 = unpickle('./cifar-10-batches-py/data_batch_4')\n",
    "train_5 = unpickle('./cifar-10-batches-py/data_batch_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_1 = train_1[b'data']\n",
    "train_labels_1 = train_1[b'labels']\n",
    "train_data_2 = train_2[b'data']\n",
    "train_labels_2 = train_2[b'labels']\n",
    "train_data_3 = train_3[b'data']\n",
    "train_labels_3 = train_3[b'labels']\n",
    "train_data_4 = train_4[b'data']\n",
    "train_labels_4 = train_4[b'labels']\n",
    "train_data_5 = train_5[b'data']\n",
    "train_labels_5 = train_5[b'labels']\n",
    "\n",
    "train_data =  np.append(train_data_1, train_data_2, axis = 0)\n",
    "train_data = np.append(train_data, train_data_3, axis = 0)\n",
    "train_data = np.append(train_data, train_data_4, axis = 0)\n",
    "train_data = np.append(train_data, train_data_5, axis = 0)\n",
    "\n",
    "#print(train_data.shape) (50000,3072)\n",
    "\n",
    "train_labels = np.append(train_labels_1, train_labels_2, axis = 0)\n",
    "train_labels = np.append(train_labels, train_labels_3, axis = 0)\n",
    "train_labels = np.append(train_labels, train_labels_4, axis = 0)\n",
    "train_labels = np.append(train_labels, train_labels_5, axis = 0)\n",
    "\n",
    "\n",
    "#print(train_labels.shape) (50000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = unpickle('./cifar-10-batches-py/test_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = test[b'data']\n",
    "test_labels = test[b'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NearestNeighbor(object):\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def train(self, X, y):\n",
    "    \"\"\" X is N x D where each row is an example. Y is 1-dimension of size N \"\"\"\n",
    "    # the nearest neighbor classifier simply remembers all the training data\n",
    "    self.Xtr = X\n",
    "    self.ytr = y\n",
    "\n",
    "  def predict(self, X):\n",
    "    \"\"\" X is N x D where each row is an example we wish to predict label for \"\"\"\n",
    "    num_test = X.shape[0]\n",
    "    # lets make sure that the output type matches the input type\n",
    "    Ypred = np.zeros(num_test, dtype = self.ytr.dtype)\n",
    "\n",
    "    # loop over all test rows\n",
    "    for i in range(num_test):\n",
    "      # find the nearest training image to the i'th test image\n",
    "      # using the L1 distance (sum of absolute value differences)\n",
    "      distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1)\n",
    "      min_index = np.argmin(distances) # get the index with smallest distance\n",
    "      Ypred[i] = self.ytr[min_index] # predict the label of the nearest example\n",
    "\n",
    "    return Ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.249200\n"
     ]
    }
   ],
   "source": [
    "nn = NearestNeighbor() # create a Nearest Neighbor classifier class\n",
    "nn.train(train_data, train_labels) # train the classifier on the training images and labels\n",
    "Yte_predict = nn.predict(test_data) # predict labels on the test images\n",
    "# and now print the classification accuracy, which is the average number\n",
    "# of examples that are correctly predicted (i.e. label matches)\n",
    "print('accuracy: %f' % ( np.mean(Yte_predict == test_labels) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*Evaluate on the test set only a single time, at the very end.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Split your training set into training set and a validation set. Use validation set to tune all hyperparameters. At the end run a single time on the test set and report performance.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
